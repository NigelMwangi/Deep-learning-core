{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "354c9eaa",
   "metadata": {},
   "source": [
    "                                                                                                             Nigel Mwangi\n",
    "\n",
    "\n",
    "# Deep Learning and Codes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31e7b85",
   "metadata": {},
   "source": [
    "Deep learning is a specialized subset of ML that utilizes neural networks with multiple layers (deep networks). These layers automatically extract high-level features from raw data, enabling remarkable accuracy and performance in tasks previously challenging for traditional algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d710567b",
   "metadata": {},
   "source": [
    "## Key Architectures in Deep Learning\n",
    "a) Convolutional Neural Networks (CNNs): Specialized for image and spatial data processing.\n",
    "\n",
    "b) Recurrent Neural Networks (RNNs): Designed for sequential data like time series or language.\n",
    "\n",
    "c) Transformer Models: Power modern NLP applications like GPT and BERT."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029a94b5",
   "metadata": {},
   "source": [
    "## Requirements Before building a neural network, several prerequisites must be met:\n",
    "1. Understanding of Neural Network Basics: A solid grasp of how neural networks function, including concepts such as neurons, activation functions, weights, biases, loss functions, and optimization techniques.\n",
    "2. Mathematical Background: Knowledge of linear algebra (matrices and vectors), calculus (gradients and derivatives), probability, and statistics is beneficial.\n",
    "3. Programming Knowledge: Proficiency in Python is highly recommended since most deep learning frameworks support Python.\n",
    "4. Computational Resources: A powerful CPU or GPU is required for efficient training of deep neural networks. Cloud services such as Google Colab, AWS, or Microsoft Azure provide additional computing power.\n",
    "5. Dataset Availability: A properly curated dataset is essential for training and evaluating the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94327f93",
   "metadata": {},
   "source": [
    "## Building a Neural Network\n",
    "\n",
    " Lets build a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71ad2d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6b08b3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'keras.api._v2.keras.datasets' from 'C:\\\\Users\\\\Nigel Mwangi\\\\anaconda3\\\\envs\\\\learn-env\\\\lib\\\\site-packages\\\\keras\\\\api\\\\_v2\\\\keras\\\\datasets\\\\__init__.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting a dataset to work with\n",
    "from tensorflow import keras\n",
    "keras.datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d205fa4c",
   "metadata": {},
   "source": [
    "Decided to choose imbd, which is used for binary sentiment classification (positive or negative reviews) in movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa686473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-processed data\n",
    "imdb = keras.datasets.imdb\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "707d1234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad all sequences to the same length for consistency\n",
    "maxlen = 256\n",
    "x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = keras.preprocessing.sequence.pad_sequences(x_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630ba520",
   "metadata": {},
   "source": [
    "The main reasoning for doing this,is to enable all the reviews the same length.\n",
    "So that the reviews shorter than 256 words get padded with zeros at the beginning.\n",
    "\n",
    "and\n",
    "\n",
    "the reviews longer than 256 words get truncated to keep only the last 256 words.\n",
    "\n",
    "### 3. Define the Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aebc87b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the model architecture\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Embedding(input_dim=10000, output_dim=32, input_length=maxlen),  # Convert word indices to dense vectors\n",
    "    keras.layers.GlobalAveragePooling1D(),  # Pooling layer to flatten the output\n",
    "    keras.layers.Dense(128, activation='relu'),  # Hidden layer\n",
    "    keras.layers.Dropout(0.2),  # Prevent overfitting\n",
    "    keras.layers.Dense(1, activation='sigmoid')  # Output layer (binary classification)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90522fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9562f565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 [==============================] - 15s 18ms/step - loss: 0.4214 - accuracy: 0.8097 - val_loss: 0.2874 - val_accuracy: 0.8821\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.2271 - accuracy: 0.9120 - val_loss: 0.2843 - val_accuracy: 0.8837\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 13s 16ms/step - loss: 0.1759 - accuracy: 0.9347 - val_loss: 0.3055 - val_accuracy: 0.8778\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.1457 - accuracy: 0.9488 - val_loss: 0.3373 - val_accuracy: 0.8712\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 12s 16ms/step - loss: 0.1230 - accuracy: 0.9586 - val_loss: 0.3714 - val_accuracy: 0.8667\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.1041 - accuracy: 0.9658 - val_loss: 0.4124 - val_accuracy: 0.8605\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 13s 16ms/step - loss: 0.0900 - accuracy: 0.9720 - val_loss: 0.4558 - val_accuracy: 0.8595\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.0782 - accuracy: 0.9756 - val_loss: 0.5152 - val_accuracy: 0.8548\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.0672 - accuracy: 0.9802 - val_loss: 0.5610 - val_accuracy: 0.8477\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.0582 - accuracy: 0.9829 - val_loss: 0.6107 - val_accuracy: 0.8449\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1fdff723df0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccec2451",
   "metadata": {},
   "source": [
    "### Evaluating model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "095e45b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 2s 2ms/step - loss: 0.6107 - accuracy: 0.8449\n",
      "Accuracy: 0.8449\n",
      "782/782 [==============================] - 2s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "#Evaluate and make predictions\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(f'Accuracy: {test_acc:.4f}')\n",
    "\n",
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54ffb861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted sentiment (probability): 0.0486\n",
      "Predicted label: Negative\n",
      "Actual label: Negative\n"
     ]
    }
   ],
   "source": [
    "#Visualize the Predictions made\n",
    "print(f'Predicted sentiment (probability): {predictions[0][0]:.4f}')\n",
    "print(f'Predicted label: {\"Positive\" if predictions[0][0] > 0.5 else \"Negative\"}')\n",
    "print(f'Actual label: {\"Positive\" if y_test[0] == 1 else \"Negative\"}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199f2147",
   "metadata": {},
   "source": [
    "Since it's text, we just show the predicted probability and label.\n",
    "\n",
    "\n",
    "This demonstrates a simple yet effective neural network for digit classification. The same methodology can be extended to more complex applications such as object detection, speech recognition, and medical diagnosis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4ad0dc",
   "metadata": {},
   "source": [
    "# Tensorflow\n",
    "\n",
    "TensorFlow is an open-source machine learning framework developed by Google Brain. It is widely used for building and training deep learning models. TensorFlow provides a flexible ecosystem of tools, libraries, and community resources that allow researchers and developers to implement state-of-the-art machine learning applications efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f4c536e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3bd0e916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data: y = 3x + 2\n",
    "X_train = np.array([1, 2, 3, 4, 5], dtype=np.float32)\n",
    "y_train = np.array([5, 8, 11, 14, 17], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e5924ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize weights and bias\n",
    "W = tf.Variable(0.0)\n",
    "b = tf.Variable(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d53ff13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate and optimizer\n",
    "learning_rate = 0.01\n",
    "optimizer = tf.optimizers.SGD(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "71124925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained parameters: W = 0.7800, b = 0.2200\n",
      "Prediction for x = 6: y = 4.90\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "# for i in range(1000):\n",
    "#     with tf.GradientTape() as tape:\n",
    "#         predictions = W * X_train + b\n",
    "#         loss = tf.reduce_mean(tf.square(predictions - y_train)) # MSE\n",
    "#         # Compute gradients and apply them\n",
    "# gradients = tape.gradient(loss, [W, b])\n",
    "# optimizer.apply_gradients(zip(gradients, [W, b]))\n",
    "\n",
    "# print(f\"Trained parameters: W = {W.numpy():.4f}, b = {b.numpy():.4f}\")\n",
    "# print(f\"Prediction for x = 6: y = {W.numpy()*6 + b.numpy():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1207679b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained parameters: W = 3.0102, b = 1.9633\n",
      "Prediction for x = 6: y = 20.02\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for i in range(1000):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = W * X_train + b\n",
    "        loss = tf.reduce_mean(tf.square(predictions - y_train))\n",
    "    gradients = tape.gradient(loss, [W, b])\n",
    "    optimizer.apply_gradients(zip(gradients, [W, b]))\n",
    "\n",
    "# Output\n",
    "print(f\"Trained parameters: W = {W.numpy():.4f}, b = {b.numpy():.4f}\")\n",
    "print(f\"Prediction for x = 6: y = {W.numpy() * 6 + b.numpy():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1607d534",
   "metadata": {},
   "source": [
    "This example demonstrates how TensorFlow trains a simple linear regression model using gradient descent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453d74f9",
   "metadata": {},
   "source": [
    "## Multi-Layer Perceptron (MLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe3f282",
   "metadata": {},
   "source": [
    "Multi-Layer Perceptron (MLP) networks are a class of artificial neural networks that consist of multiple layers of neurons, including an input layer, one or more hidden layers, and an output layer. MLP networks use supervised learning techniques and backpropagation for training. These networks are widely used in various fields such as image recognition, speech processing, and financial forecasting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b323e3b",
   "metadata": {},
   "source": [
    "### Basics of Neural Networks\n",
    "\n",
    "A neural network is a computational model inspired by the structure and function of biological neural networks in the brain. It consists of layers of artificial neurons that process input data and produce outputs based on learned patterns.\n",
    "Components of a Neural Network\n",
    "\n",
    "1. Neurons: Basic processing units that receive weighted inputs, apply an activation function, and pass output to the next layer.\n",
    "2. Layers:\n",
    "-  Input Layer: Accepts raw data.\n",
    "-  Hidden Layers: Perform feature extraction and transformation.\n",
    "-  Output Layer: Produces the final prediction or classification.\n",
    "3. Weights and Biases: Adjustable parameters that determine how neurons process inputs.\n",
    "4. Activation Functions: Introduce non-linearity to enable learning of complex patterns.\n",
    "\n",
    "Example: A neural network predicting house prices based on features like location, size, and number of bedrooms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e46f131",
   "metadata": {},
   "source": [
    "## Hands-On: Using an MLP,  Multi-Layer Perceptron (MLP) networks\n",
    "## Practical Implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d1c0fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad05d370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af399d0b",
   "metadata": {},
   "source": [
    "#### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "207b688f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define MLP model\n",
    "model = Sequential([\n",
    "Flatten(input_shape=(28, 28)),\n",
    "Dense(128, activation='relu'),\n",
    "Dense(64, activation='relu'),\n",
    "Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc1bae6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.2438 - accuracy: 0.9292 - val_loss: 0.1332 - val_accuracy: 0.9587\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.1016 - accuracy: 0.9692 - val_loss: 0.1033 - val_accuracy: 0.9694\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0715 - accuracy: 0.9779 - val_loss: 0.0712 - val_accuracy: 0.9769\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0525 - accuracy: 0.9832 - val_loss: 0.0757 - val_accuracy: 0.9772\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0409 - accuracy: 0.9868 - val_loss: 0.0841 - val_accuracy: 0.9748\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0342 - accuracy: 0.9890 - val_loss: 0.0831 - val_accuracy: 0.9765\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0268 - accuracy: 0.9907 - val_loss: 0.0910 - val_accuracy: 0.9756\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0222 - accuracy: 0.9926 - val_loss: 0.0927 - val_accuracy: 0.9766\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0209 - accuracy: 0.9926 - val_loss: 0.0815 - val_accuracy: 0.9786\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.0197 - accuracy: 0.9933 - val_loss: 0.1044 - val_accuracy: 0.9772\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x22593be50c0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile and train model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14077a6",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb33c926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1044 - accuracy: 0.9772\n",
      "Test accuracy: 0.9772\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(f'Test accuracy: {test_acc:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e581e3b5",
   "metadata": {},
   "source": [
    "## Convolutional Neural Networks (CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aeeb491",
   "metadata": {},
   "source": [
    "Convolutional Neural Networks (CNNs) are specialized deep learning architectures designed primarily for image processing tasks. They utilize a series of convolutional layers to extract hierarchical features from images, making them highly effective for visual recognition\n",
    "\n",
    "Working Example\n",
    "Let's implement a basic CNN using TensorFlow and Keras to classify handwritten digits from the MNIST dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a36708a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.datasets import mnist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "204662b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data \n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0 # Normalize\n",
    "x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace796ce",
   "metadata": {},
   "source": [
    "### Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54fca27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CNN model\n",
    "model = models.Sequential([\n",
    "layers.Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)),\n",
    "layers.MaxPooling2D((2,2)),\n",
    "layers.Conv2D(64, (3,3), activation='relu'),\n",
    "layers.MaxPooling2D((2,2)),\n",
    "layers.Flatten(),\n",
    "layers.Dense(128, activation='relu'),\n",
    "layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045e9092",
   "metadata": {},
   "source": [
    "A small description, \n",
    "\n",
    "1. Conv2D -  filters of size 3×3, detects patterns/features\n",
    "\n",
    "2. MaxPooling2D - \tDownsamples to reduce size and computation\n",
    "\n",
    "3. Conv2D -\t64 filters, deeper features\n",
    "\n",
    "4. MaxPooling2D -\tDownsampling again\n",
    "\n",
    "5. Flatten() - \tConverts 2D output into 1D\n",
    "\n",
    "6. Dense(128) - Fully connected layer with 128 neurons\n",
    "7. Dense(10, softmax)\t- Output layer for 10 digit classes (0–9) with probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec37eede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 75s 39ms/step - loss: 0.1259 - accuracy: 0.9619 - val_loss: 0.0429 - val_accuracy: 0.9858\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 71s 38ms/step - loss: 0.0401 - accuracy: 0.9875 - val_loss: 0.0339 - val_accuracy: 0.9885\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 73s 39ms/step - loss: 0.0280 - accuracy: 0.9910 - val_loss: 0.0283 - val_accuracy: 0.9904\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 70s 37ms/step - loss: 0.0191 - accuracy: 0.9941 - val_loss: 0.0269 - val_accuracy: 0.9909\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 72s 38ms/step - loss: 0.0145 - accuracy: 0.9954 - val_loss: 0.0301 - val_accuracy: 0.9908\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x22596431d80>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile and train the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ece3d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0301 - accuracy: 0.9908\n",
      "Test Accuracy: 0.9908\n"
     ]
    }
   ],
   "source": [
    "# Evaluate and print accuracy\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83878b6e",
   "metadata": {},
   "source": [
    "This likely means validation accuracy = 99.08% after training. Very high performance — CNNs perform much better than basic MLPs on image tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774d4450",
   "metadata": {},
   "source": [
    "Application Areas\n",
    "CNNs are widely used in:\n",
    "-  Medical Imaging: Detecting anomalies in X-rays and MRIs.\n",
    "- Autonomous Vehicles: Enabling real-time object recognition.\n",
    "- Augmented Reality (AR): Enhancing user interactions with the environment.\n",
    "- Security Systems: Facial recognition and surveillance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1e1712",
   "metadata": {},
   "source": [
    "## Recurrent Neural Networks (RNN)\n",
    "\n",
    "A Recurrent Neural Network (RNN) is a class of artificial neural networks designed to recognize patterns in sequences of data, such as time series, speech, text, or video frames.\n",
    "\n",
    "Key Concept: Unlike traditional neural networks, RNNs have loops in them, allowing information to persist. This makes them suitable for sequential data where current output depends on previous computations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19dd093",
   "metadata": {},
   "source": [
    "### Practical Example: Text Sentiment Classification\n",
    "\n",
    "Problem:\n",
    "Classify the sentiment (positive/negative) of a sentence using an RNN.\n",
    "\n",
    "Dataset:\n",
    "A sample dataset like the IMDB movie review dataset (each entry is a review labeled as positive or negative)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7abc590",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40f907ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "vocab_size = 10000\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ad7ed2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad sequences\n",
    "maxlen = 500\n",
    "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = pad_sequences(x_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6eee4d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 32))\n",
    "model.add(SimpleRNN(32))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d5fffb",
   "metadata": {},
   "source": [
    "A small explanaton of the model,\n",
    "\n",
    "- Embedding(10000, 32)- Converts each word index into a 32-dimensional vector. Input shape becomes (batch_size, 500, 32)\n",
    "- SimpleRNN(32) - \tProcesses the sequence of embeddings using 32 recurrent units. Outputs a single vector (last hidden state)\n",
    "- Dense(1, activation='sigmoid') - \tOutputs a value between 0 and 1 — the probability that the review is positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86cd6c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "391/391 [==============================] - 110s 275ms/step - loss: 0.5972 - accuracy: 0.6626 - val_loss: 0.4362 - val_accuracy: 0.8084\n",
      "Epoch 2/5\n",
      "391/391 [==============================] - 110s 281ms/step - loss: 0.4179 - accuracy: 0.8081 - val_loss: 0.4011 - val_accuracy: 0.8307\n",
      "Epoch 3/5\n",
      "391/391 [==============================] - 109s 278ms/step - loss: 0.2837 - accuracy: 0.8846 - val_loss: 0.4370 - val_accuracy: 0.8178\n",
      "Epoch 4/5\n",
      "391/391 [==============================] - 104s 266ms/step - loss: 0.2024 - accuracy: 0.9222 - val_loss: 0.4566 - val_accuracy: 0.8258\n",
      "Epoch 5/5\n",
      "391/391 [==============================] - 106s 270ms/step - loss: 0.0945 - accuracy: 0.9680 - val_loss: 0.5292 - val_accuracy: 0.8175\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x22594e1c1c0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile and train\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=5, batch_size=64, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba9b1626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 30s 38ms/step - loss: 0.5292 - accuracy: 0.8175\n",
      "Test Accuracy: 0.8175\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "\n",
    "# Print the test accuracy\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0977892",
   "metadata": {},
   "source": [
    "This shows that the trained RNN correctly classifies 81.75% of the IMDB reviews on the test set. This is decent performance, especially for a basic SimpleRNN. \n",
    "\n",
    "Benefits of RNN:\n",
    "- Captures context and sequence (e.g., \"not good\" vs \"very good\").\n",
    "- Learns temporal dependencies that MLPs would miss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152fcd10",
   "metadata": {},
   "source": [
    "## Long Short-Term Memory (LSTM)\n",
    "\n",
    "LSTM is a special type of Recurrent Neural Network (RNN) capable of learning long-term dependencies. It was introduced by Hochreiter and Schmidhuber in 1997 to address the vanishing gradient problem common in standard RNNs.\n",
    "\n",
    "Core Idea: LSTM introduces a memory cell and gates (input, forget, and output) that regulate the flow of information, allowing it to retain or forget information over long sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878ff436",
   "metadata": {},
   "source": [
    "Working Example: Sentiment Analysis with LSTM\n",
    "\n",
    "Dataset: We'll use the IMDB movie review dataset for binary sentiment classification (positive or negative).\n",
    "\n",
    "Hands-On practical with working with LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "064a3aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49622646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load IMDB dataset (pre-tokenized)\n",
    "vocab_size = 10000\n",
    "maxlen = 500\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55d45ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad sequences to have equal length\n",
    "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = pad_sequences(x_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498ed967",
   "metadata": {},
   "source": [
    "Aan explanation on this pad sequences, \n",
    "\n",
    "- Ensures that all sequences are exactly 500 tokens long.\n",
    "\n",
    "- Shorter reviews are zero-padded at the beginning.\n",
    "\n",
    "This is required so the model receives a consistent input shape: (batch_size, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e85cea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define LSTM model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 64, input_length=maxlen))\n",
    "model.add(LSTM(64)) # Main LSTM layer\n",
    "model.add(Dense(1, activation='sigmoid')) # Output layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67539dd4",
   "metadata": {},
   "source": [
    "A small explanation on the model is that,\n",
    "\n",
    "- Embedding\t- Transforms word indices into dense vectors (64-dim). Input: (batch_size, 500) → Output: (batch_size, 500, 64)\n",
    "- LSTM(64) - Learns sequential patterns using 64 memory cells. Processes all 500 time steps and outputs a 64-length vector\n",
    "- Dense(1, sigmoid) - Outputs a probability between 0 and 1 for binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "02302b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d909f05",
   "metadata": {},
   "source": [
    "\n",
    "- Adam optimizer, shows Efficient gradient descent.\n",
    "- Binary crossentropy, Appropriate for binary output.\n",
    "- Accuracy, giving the Evaluation metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b0cce52c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "391/391 [==============================] - 447s 1s/step - loss: 0.4221 - accuracy: 0.7985 - val_loss: 0.4294 - val_accuracy: 0.8319\n",
      "Epoch 2/3\n",
      "391/391 [==============================] - 499s 1s/step - loss: 0.2614 - accuracy: 0.8988 - val_loss: 0.3318 - val_accuracy: 0.8599\n",
      "Epoch 3/3\n",
      "391/391 [==============================] - 425s 1s/step - loss: 0.1988 - accuracy: 0.9260 - val_loss: 0.3373 - val_accuracy: 0.8703\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x225968b7970>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model\n",
    "model.fit(x_train, y_train, epochs=3, batch_size=64, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c8deb6",
   "metadata": {},
   "source": [
    "#### Evaluation of what our model shows us\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "62017700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 119s 152ms/step - loss: 0.3373 - accuracy: 0.8703\n",
      "Test Accuracy: 0.8703\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a88f87",
   "metadata": {},
   "source": [
    "The model correctly predicted the sentiment (positive or negative) for approximately 87.03% of the 25,000 reviews in the test dataset.\n",
    "\n",
    "An accuracy above 85% using just a basic LSTM without any additional enhancements (like dropout, bidirectional layers, or pre-trained embeddings) is quite solid."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fa0fe6",
   "metadata": {},
   "source": [
    "## Recursive Neural Networks (RecNNs)\n",
    "\n",
    "Recursion is a programming concept where a function calls itself to solve a problem by breaking it down into smaller sub-problems of the same type.\n",
    "\n",
    "Recursive Neural Networks (not to be confused with Recurrent Neural Networks) are deep learning models designed for structured input, such as trees. They apply the same set of weights recursively over a hierarchical structure (typically a tree) to extract structured representations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054e4a4d",
   "metadata": {},
   "source": [
    "How Recursive Neural Networks Work\n",
    "-  Input: A parse tree or syntactic structure.\n",
    "- Process: Combine leaf node embeddings into parent nodes recursively using a neural function.\n",
    "- Output: A representation at the root node that summarizes the whole structure (e.g., a sentence)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e228fc",
   "metadata": {},
   "source": [
    "Hands-On: Using a Recursive Neural Network (Simulated Example in PyTorch)\n",
    "\n",
    "Recursive Neural Networks aren't built into high-level APIs like Keras or PyTorch out-of-the-box because they require custom tree data structures. Below is a simplified simulated example of how you might implement one manually for binary parse trees.\n",
    "\n",
    "Example: Binary Tree Sentiment Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72453a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# installing pytorch \n",
    "#!pip install torch torchvision torchaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d69ce7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b28d2d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample tree node class\n",
    "class TreeNode:\n",
    "    def __init__(self, left=None, right=None, value=None):\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.value = value # Word embedding or input vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0feb6a8a",
   "metadata": {},
   "source": [
    "Explanation on this is, \n",
    "- TreeNode\tRepresents a node in a syntax/parse tree\n",
    "- value\tA tensor (vector) holding word or phrase encoding\n",
    "- left/right\tPointers to child nodes (for recursive traversal)\n",
    "- Used in\tSentiment analysis, syntax trees, question answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fc672fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recursive Neural Network\n",
    "class RecNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(RecNN, self).__init__()\n",
    "        self.W = nn.Linear(2 * hidden_dim, hidden_dim)\n",
    "        self.embedding = nn.Embedding(10000, input_dim)\n",
    "        self.projection = nn.Linear(input_dim, hidden_dim)\n",
    "        \n",
    "    def forward(self, node):\n",
    "        if node.left is None and node.right is None:\n",
    "            # Leaf node: use embedding\n",
    "            embed = self.embedding(torch.tensor([node.value]))\n",
    "            return self.projection(embed).squeeze(0)\n",
    "        else:\n",
    "            left_vec = self.forward(node.left)\n",
    "            right_vec = self.forward(node.right)\n",
    "            combined = torch.cat((left_vec, right_vec), dim=-1)\n",
    "            return F.relu(self.W(combined))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b38dde",
   "metadata": {},
   "source": [
    "Also,\n",
    "- self.embedding\tTurns word indices into dense vectors (input_dim)\n",
    "- self.projection\tProjects embedding into hidden_dim space (for recursive operations)\n",
    "- self.W\tComposes two child vectors into a parent vector\n",
    "\n",
    "Leaf nodes: Get embedded word vector → projected to hidden_dim\n",
    "\n",
    "Non-leaf nodes:\n",
    "\n",
    "- Recursively get left and right vectors\n",
    "- Concatenate them: left_vec ,  right_vec]\n",
    "- Apply linear layer and ReLU activation to get the parent vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "776ffac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tree structure: (great (not movie))\n",
    "left_leaf = TreeNode(value=2)     # \"not\"\n",
    "right_leaf = TreeNode(value=3)    # \"movie\"\n",
    "intermediate = TreeNode(left=left_leaf, right=right_leaf)  # (not movie)\n",
    "root = TreeNode(left=TreeNode(value=1), right=intermediate)  # (great (not movie))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d2c4f5",
   "metadata": {},
   "source": [
    "    root\n",
    "         /    \\\n",
    "     \"great\"   node\n",
    "               /   \\\n",
    "           \"not\"  \"movie\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "554987b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final representation vector: tensor([0.0000, 0.0000, 0.3416, 0.2859, 0.0000, 0.4300, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.4691, 0.2243, 0.1359, 0.0262, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.3079, 0.4697, 0.1843, 0.1431, 0.0000, 0.1022, 0.0000, 0.3758, 0.0000,\n",
      "        0.2991, 0.0000, 0.0847, 0.1217, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0505, 0.9173, 0.0000, 0.6391, 0.0000, 0.0000, 0.0000, 0.0000, 0.0653,\n",
      "        0.5322, 0.0908, 0.1840, 0.0767, 0.0000, 0.2456, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.2046, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0981], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = RecNN(input_dim=50, hidden_dim=64)\n",
    "sentence_vector = model(root)\n",
    "\n",
    "print(\"Final representation vector:\", sentence_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f078131b",
   "metadata": {},
   "source": [
    "This runs a recursive forward pass from leaves up to the root.\n",
    "\n",
    "The result is a 64-dimensional vector that represents the entire sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddeb3cd2",
   "metadata": {},
   "source": [
    "Lets give a short visualization to understand what is happening,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95ee7d21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Detach from computation graph and convert to numpy\n",
    "vec = sentence_vector.detach().numpy()\n",
    "\n",
    "# Plot the 64-dimensional sentence vector\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.bar(range(len(vec)), vec)\n",
    "plt.title(\"Final Sentence Vector (64 dimensions)\")\n",
    "plt.xlabel(\"Dimension Index\")\n",
    "plt.ylabel(\"Activation Value\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3af1b70",
   "metadata": {},
   "source": [
    "Each bar represents the value of a single neuron in the final vector output of your RecNN.\n",
    "\n",
    "Peaks in the plot indicate strong activations, potentially tied to certain patterns in the sentence.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557599ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
